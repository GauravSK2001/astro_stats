{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "plt.rcParams['xtick.minor.visible'], plt.rcParams['xtick.top'] = True,True \n",
    "plt.rcParams['ytick.minor.visible'], plt.rcParams['ytick.right'] = True,True \n",
    "plt.rcParams['xtick.direction'], plt.rcParams['ytick.direction'] = 'in','in' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 18 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Our data are measurements of the velocity dispersion ($\\sigma$) and absolute magnitude $m_0$ of elliptical galaxies \n",
    "\n",
    "### These come from Schechter (1980), and are used to look at the Faber-Jackson relation, which says that the two properties are related through a power law, i.e. $L\\propto\\sigma^{\\gamma}$, where $\\gamma$ is unknown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We read in the data, and convert the 'absolute' magnitude (applying a correction to put it in terms of Solar luminosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df = np.loadtxt('Sigma_M0.csv',\n",
    "                delimiter=',',skiprows=1)\n",
    "sigma = df[:,0]\n",
    "m0 = df[:,1] \n",
    "L = 3e14*np.power(10,-m0/2.5)\n",
    "\n",
    "log_sigma = np.log10(sigma)\n",
    "log_L = np.log10(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(log_sigma,log_L,'.')\n",
    "plt.xlim(2,2.8)\n",
    "plt.ylim(9,12)\n",
    "plt.xlabel(r'$\\log_{10}(\\sigma/km\\, s^{-1})$')\n",
    "plt.ylabel(r'$\\log_{10}(L/L_\\odot)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fit as ordinary least squares $\\log L = a + b \\log \\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Functions that I will require: \n",
    "# np.matmul() - multiply matrices\n",
    "# np.linalg.inv() - invert a matrix\n",
    "A = np.zeros((len(log_sigma),2))\n",
    "A[:,0] = 1.\n",
    "A[:,1] = log_sigma\n",
    "#ab = np.matmul(np.matmul(np.linalg.inv(np.matmul(A.T,A)),A.T),log_L.T)\n",
    "ab = np.matmul(np.matmul(np.linalg.inv(np.matmul(A.T,A)),A.T),log_L.T)\n",
    "plt.plot(log_sigma,log_L,'.')\n",
    "plt.xlim(2,2.8)\n",
    "plt.ylim(9,12)\n",
    "plt.xlabel(r'$\\log_{10}(\\sigma/km\\, s^{-1})$')\n",
    "plt.ylabel(r'$\\log_{10}(L/L_\\odot)$')\n",
    "\n",
    "xline = np.array([2,2.8])\n",
    "yline = ab[0]+ab[1]*xline\n",
    "plt.plot(xline,yline)\n",
    "\n",
    "plt.title(f'$L \\propto \\sigma^{{{ab[1]:4.2f}}}$')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But also fit as $\\log \\sigma = c + d \\log L$ \n",
    "\n",
    "# One might expect a very similar result...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "A2 = np.zeros((len(log_L),2))\n",
    "A2[:,0] = 1.\n",
    "A2[:,1] = log_L\n",
    "cd = np.matmul(np.matmul(np.linalg.inv(np.matmul(A2.T,A2)),A2.T),log_sigma.T)\n",
    "\n",
    "\n",
    "plt.plot(log_L,log_sigma,'.')\n",
    "plt.ylim(2,2.8)\n",
    "plt.xlim(9,12)\n",
    "plt.ylabel(r'$\\log_{10}(\\sigma/km\\, s^{-1})$')\n",
    "plt.xlabel(r'$\\log_{10}(L/L_\\odot)$')\n",
    "\n",
    "yline2 = np.array([9,12])\n",
    "xline2 = cd[0]+cd[1]*yline\n",
    "#print('gamma = ', 1./cd[1])\n",
    "\n",
    "plt.plot(yline2,xline2)\n",
    "plt.title('Note flip of axes')\n",
    "plt.title(f'$L \\propto \\sigma^{{{1/cd[1]:4.2f}}}$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why is this?\n",
    "\n",
    "## Think about the models we are (implicitly) fitting here: \n",
    "\n",
    "$\\log L_i = a + b \\log \\sigma_i + e_i$ \n",
    "\n",
    "where $e_i \\sim N(0,\\sigma)$\n",
    "\n",
    "OR\n",
    "\n",
    "\n",
    "$\\log \\sigma_i = a + b \\log L_i + e_i$ \n",
    "\n",
    "where $e_i \\sim N(0,\\sigma)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2,figsize=(12,5))\n",
    "#plt.errorbar()\n",
    "# Make up some plausibly-sized errorbars\n",
    "ax[0].errorbar(log_sigma,log_L,yerr=0.5,fmt='x')\n",
    "ax[1].errorbar(log_sigma,log_L,xerr=0.1,fmt='x')\n",
    "for i in [0,1] :\n",
    "    ax[i].set_xlim(2,2.8)\n",
    "    ax[i].set_ylim(9,12)\n",
    "    ax[i].set_xlabel(r'$\\log_{10}(\\sigma/km\\, s^{-1})$')\n",
    "    ax[i].set_ylabel(r'$\\log_{10}(L/L_\\odot)$')\n",
    "ax[0].set_title(r'Fit $\\log L = a + b\\,\\log \\sigma$')\n",
    "ax[1].set_title(r'Fit $\\log \\sigma = c + d\\,\\log L$')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## So, remember that this sort of approach is only valid if we can assume that the uncertainties on one value are negligible (and that this dictates what we fit against what)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I recommend looking at the online guide \"Data analysis recipes: Fitting a model to data\" by Hogg, Bovy \\& Lang (https://arxiv.org/abs/1008.4686) if you want to look in to this more.\n",
    "\n",
    "Here, there is no direct causal link going from $\\sigma$ to $L$ or vice versa: rather, both are governed by the mass of the galaxy (and extra factors). So there are no \"dependent\" and \"independent\" variables. What is fitted against what depends on the uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In fact the product of the two gradients is $r^2$, where r is the sample correlation coefficient \n",
    "\n",
    "There is a sad history of saying 'well, we should take the line that bisects these two as the true best fit'. This is statistically unjustified. Hogg et al are, rightly, scathing about it. They also talk about more complete (maximum likelihood, or similar) approaches that should be taken."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
