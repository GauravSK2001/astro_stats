{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33758621-2795-42ce-9838-41caa1dd74f4",
   "metadata": {},
   "source": [
    "# Demonstration of hypothesis testing\n",
    "\n",
    "This notebook demonstrates Frequentist and Bayesian approaches to hypothesis testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb2d8ac-ce1a-4c4e-8b7d-cf7156d7b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy import special\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367926ed-b834-4193-8969-5cb0e7bd9a8a",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "Sun-like stars have a binary fraction of around 50% ($f_\\odot=0.5$). We observe a sample of $N$ stars and wish to know whether the binary fraction is consistent with $f=f_\\odot=0.5$ or whether it differs. In particular, we have reason to suspect that $f>0.5$ for the kind of stars we are studying.\n",
    "\n",
    "Assume we can always detect a binary companion if present.\n",
    "\n",
    "We observe $N=30$ stars, and find that $k=20$ have binary companions. Is this consistent with $f_\\odot=0.5$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326c14a-971a-4db8-87ce-dbb53d41fa8a",
   "metadata": {},
   "source": [
    "## Frequentist approach 1: the binomial test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c22a7-dfc5-4791-a208-fec36cbccb1e",
   "metadata": {},
   "source": [
    "Our survey is an example of a *binomial* experiment: a set of $N$ independent trials each of which has a fixed probability of success $f$. The number of binaries detected, $K$, then follows a binomial distribution with parameters $N$ and $f$. This has a probability mass function\n",
    "\n",
    "$P(K=k) = \\frac{N!}{k!(N-k)!}f^{k}(1-f)^{N-k}$\n",
    "\n",
    "We can now state our null and alternative hypotheses mathematically: \n",
    " - $H_0$: $K\\sim\\mathrm{Binomial}(N,f)$ where $f=0.5$\n",
    " - $H_1$: $f>0.5$\n",
    "\n",
    "We choose $\\alpha=0.05$ as our significance level.\n",
    "\n",
    "Can we reject $H_0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c615e8a-024c-4ca3-ab0d-25998b2a34df",
   "metadata": {},
   "source": [
    "As we suspect $f>0.5$, we conduct a one-tailed test. Let's calculate the PMF for our binomial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df526e02-aece-42f7-aa17-af028b59fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.arange(0,31)\n",
    "N = 30\n",
    "f = 0.5\n",
    "alpha=0.05\n",
    "k_obs = 20\n",
    "# brute-force this. Note that factorials can get BIG and you'll want to be more clever if N gets too large\n",
    "\n",
    "pmf = special.factorial(N)/(special.factorial(k)*special.factorial(N-k)) * f**k * (1-f)**(N-k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318eaa05-67ca-4012-9213-dab4bdbb0a20",
   "metadata": {},
   "source": [
    "check our numerical accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ba45aa-8594-4bf9-a081-b181cfd582ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(pmf))\n",
    "pmf = pmf/np.sum(pmf)\n",
    "cdf = np.cumsum(pmf)\n",
    "cdf = np.hstack([[0],cdf]) # Bet you didn't see this coming!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7844e9f-b44a-478b-b552-1ac083e3191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.bar(k,pmf,color='pink',label='pmf')\n",
    "ax.set_ylim(0,.15)\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('pmf')\n",
    "ax2 = ax.twinx()\n",
    "plt.plot(k,cdf[:-1],c='k',label='cdf')\n",
    "ax2.set_ylim(0,1)\n",
    "ax2.set_ylabel('cdf')\n",
    "ax2.plot([0,N],[1-alpha,1-alpha],'-.',label='$alpha=0.05$',color='blue')\n",
    "ax2.plot([k_obs,k_obs],[0,1],c='gray',label='$k=20$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca753d0-78da-4771-8154-1ab811c16858",
   "metadata": {},
   "source": [
    "We see that $k=20$ lies out in the tail of the distribution with the cdf $>1-\\alpha=0.95$. We can quantify this a little more by tabulating the cumulative distribution function around that region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62bef32-e359-4227-a405-f066f51342c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('k      cdf')\n",
    "for i in range(10):\n",
    "    print(k[i + 15],cdf[i + 15])\n",
    "\n",
    "print(f'The p-value is {1-cdf[20]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e5b998-d53c-4b5c-96f3-997b1bcc230c",
   "metadata": {},
   "source": [
    "Any $k\\ge20$ would be sufficient to reject the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4828cb7-35a4-478e-b68a-c8bf3cd4ccac",
   "metadata": {},
   "source": [
    "What about if we wanted to look for any deviation from $f=0.5$, not just $f>.0.5$? Then we would use a two-tailed test, and the 5% of the area of the pmf gets split between the two tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3ec065-90ae-4794-b33c-8ff924fd754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.bar(k,pmf,color='pink',label='pmf')\n",
    "ax.set_ylim(0,.15)\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('pmf')\n",
    "ax2 = ax.twinx()\n",
    "plt.plot(k,cdf[:-1],c='k',label='cdf')\n",
    "ax2.set_ylim(0,1)\n",
    "ax2.set_ylabel('cdf')\n",
    "ax2.plot([0,N],[1-alpha/2,1-alpha/2],'-.',label='$alpha=0.05$',color='blue')\n",
    "ax2.plot([k_obs,k_obs],[0,1],c='gray',label='$k=20$')\n",
    "ax2.plot([0,N],[alpha/2,alpha/2],'-.',color='blue')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fd179b-4ead-4c95-9e48-88a52b340859",
   "metadata": {},
   "source": [
    "Now we no longer have a significant result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af743eb-ad05-4025-8d24-136b588ef5ef",
   "metadata": {},
   "source": [
    "## Frequentist approach 2: the $\\chi^2$ test\n",
    "\n",
    "We can also treat this with the $\\chi^2$ test. We have two 'bins' of data --- binary and not binary --- and under our null hypothesis we would expect $E_1=N\\times f=15$ counts in the binary bin and $E_2=N\\times(1-f)=15$ in the not binary bin.\n",
    "\n",
    "Observed counts are $O_1=20$ and $O_2=10$.\n",
    "\n",
    "We have a test statistic $\\chi^2 = \\sum_{i=1}^2 \\frac{(O_i-E_i)^2}{E_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1c621-2bbc-4037-8c4d-357f5516c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2 = (k_obs-(N*f))**2 / (N*f) + ((N-k_obs)-(N*(1-f)))**2 / (N*(1-f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7067fc-205d-4b9e-b304-8300d85dea0d",
   "metadata": {},
   "source": [
    "This should follow a $\\chi^2$ distribution with 1 degree of freedom (2 bins - 1), which you can access via SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd7376-0fd4-4e90-8d19-78f9e5cf9e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2dist = stats.chi2(1) # creates a chi2 object with 1 dof\n",
    "\n",
    "x = np.linspace(0,10,1001)\n",
    "plt.plot(x,chi2dist.cdf(x),label='cdf') # this accesses the cumulative distribution function\n",
    "c95 = chi2dist.ppf(.95) # the \"percent point function\": use this to get the critical values\n",
    "plt.plot([x[0],x[-1]],[0.95,0.95],label='alpha=0.05')\n",
    "plt.plot([c95,c95],[0,1],label='critical value')\n",
    "plt.plot([chi2,chi2],[0,1],label='observed value')\n",
    "plt.xlabel('chi2')\n",
    "plt.ylabel('cdf')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0984ec4e-6fb8-417f-b900-efafdd71c453",
   "metadata": {},
   "source": [
    "On this test, we again don't get a significnat result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68dd249-0a00-42ed-9a56-ad5610074028",
   "metadata": {},
   "source": [
    "## Digression on $\\chi^2$ degrees of freedom\n",
    "\n",
    "The choice of $\\nu=n-1$ for the degrees of freedom may seem curious. Let's test it (demonstrating the concept of a sampling distribution in the process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9833d6b5-fe55-411d-9fe1-2850f6899222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a pseudo-random number generator\n",
    "rng = np.random.default_rng(376452)\n",
    "\n",
    "# a large sample to avoid small number stats and discretisation effects. We'll set up 1e5 samples each of size 1e4\n",
    "size = 10000\n",
    "n_samples = 100000\n",
    "O1 = rng.binomial(size,f,n_samples) #I could have done this earlier, but wanted to show an explicit calculation\n",
    "O1 = np.vstack([O1,size-O1]) # simulated bins of binaries and non-binaries\n",
    "E1 = np.outer(np.array([size*f,size*(1-f)]),np.ones(n_samples))\n",
    "chisq1 = np.sum((O1-E1)**2/E1,0) # get the chi2 for each 1e5 samples\n",
    "khisq1 = stats.chi2(1) # the theoretical distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce908d3-a9ac-40cd-928d-d83827840090",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(0,10)\n",
    "plt.hist(chisq1,bins=x,density=True,label='Monte-Carlo samples')\n",
    "plt.plot(x,khisq1.pdf(x),label='theoretical, 1dof') # scipy can give us the pdf too\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e2d87-c68e-49fc-b2d8-55ba8feca127",
   "metadata": {},
   "source": [
    "A pretty good match! Here we fixed the number of stars per sample at 1e4. This seems to validate the intuition that we fix the total number, so when we specify the count in one bin we also fix that in the other. Hence we have 1 dof, not 2\n",
    "\n",
    "But what happens if we allow each bin to be populated independently? Let's make a set of Poisson samples where binary plus non-binary does not necessarily add to 1e4..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632907b7-74e7-4f0f-a281-b371506a32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "O2 = np.vstack([rng.poisson(size*f,n_samples),rng.poisson(size*(1-f),n_samples)])\n",
    "n2 = np.sum(O2,0)\n",
    "plt.hist(n2)\n",
    "plt.title('Different number in each sample')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db8fb5c-5b77-4ac6-9a0e-7a78cd9d1801",
   "metadata": {},
   "outputs": [],
   "source": [
    "E2 = np.vstack([n2*f,n2*(1-f)])\n",
    "chisq2 = np.sum((O2-E2)**2/E2,0)\n",
    "khisq2 = stats.chi2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9e4c4-0e50-4bb7-9c79-c07c11968571",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(0,10)\n",
    "plt.hist(chisq2,bins=x,density=True,label='Monte-Carlo samples')\n",
    "plt.plot(x,khisq1.pdf(x),label='theoretical, 1dof')\n",
    "plt.plot(x,khisq2.pdf(x),label='theoretical, 2dof')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d159e3-f548-4a82-8fe6-67d10dbf9001",
   "metadata": {},
   "source": [
    "Curiously, this still follows the $\\chi^2$ distribution with one degree of freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cd1eb3-5510-430e-9cf8-bd5e07b1c648",
   "metadata": {},
   "source": [
    "## Bayesian approach\n",
    "\n",
    "Our background information $I$ specifies two models:\n",
    " - $M_1$: $K\\sim\\mathrm{Binomial}(N,f)$ with $f=0.5$\n",
    " - $M_2$: $K\\sim\\mathrm{Binomial}(N,f)$ with a uniform prior on $f$ from 0 to 1\n",
    "\n",
    "We can easily compute the evidence/marginal likelihood for $M_1$, $P(D|M_1,I)=\\frac{N!}{k!(N-k)!}f^{k}(1-f)^{N-k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b476f7a-2f3a-4fce-84f4-43a0dd3e767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evidence1 = pmf[k_obs]\n",
    "print(Evidence1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4c9516-2b88-43f5-8ad0-76f9235fa8a1",
   "metadata": {},
   "source": [
    "For $M_2$ we have to work harder and marginalise (integrate) over the free parameter:\n",
    "\n",
    "$P(D|M_2,I) = \\int_0^1P(D|f,M_2,I)P(f|M_2,I)df$ = 1/(N+1) after some algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab8a1af-0385-44fa-9dd1-d0834dd932c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evidence2 = 1/(N+1)\n",
    "print(Evidence2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed56861-1036-40c3-bc84-d22b05b83034",
   "metadata": {},
   "source": [
    "Very similar! Now we have our Bayes Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b34d0-fe50-46d3-ae80-1afdc48a2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayes = Evidence2/Evidence1\n",
    "logBayes = np.log10(Bayes)\n",
    "print(f'Bayes Factor: {Bayes}')\n",
    "print(f'log scale:    {logBayes*10} db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81116f0d-fd6f-4bfd-aa7f-98794709edd1",
   "metadata": {},
   "source": [
    "*I.e.,* no strong evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f8890-1810-4d2e-9aff-f6fe1d15fd17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
